{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Rotational Motions for Source Tracking\n",
    "\n",
    "   <img src=\"pictures/Merapi_Net2001.png\" alt=\"Merapi Array\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import optparse\n",
    "import matplotlib\n",
    "#matplotlib.use(\"agg\")\n",
    "from obspy import *\n",
    "from obspy.core import AttribDict\n",
    "import obspy.signal.array_analysis as AA\n",
    "import obspy.signal.util as util\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import time\n",
    "from obspy.signal.rotate import rotate2zne\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "from obspy.clients.filesystem import sds\n",
    "import scipy as sp\n",
    "import scipy.odr as odr\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation of \"Array-Derived-Rotation\" (ADR) using the $L_2$ norm algorithm of Spudich and Fletcher (2008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## array_rotation_strain(subarray, ts1, ts2, ts3, vp, vs, array_coords, sigmau)\n",
    "\n",
    "### vp (float)\n",
    "P wave speed in the soil under the array (km/s)\n",
    "\n",
    "### vs (float)\n",
    "S wave speed in the soil under the array Note - vp and vs may be any unit (e.g. miles/week), and this unit need not be related to the units of the station coordinates or ground motions, but the units of vp and vs must be the SAME because only their ratio is used.\n",
    "\n",
    "### array_coords (numpy.ndarray)\n",
    "array of dimension na x 3, where na is the number of stations in the array. array_coords[i,j], i in arange(na), j in arange(3) is j coordinate of station i. units of array_coords may be anything, but see the “Discussion of input and output units” above. The origin of coordinates is arbitrary and does not affect the calculated strains and rotations. Stations may be entered in any order.\n",
    "\n",
    "### ts1 (numpy.ndarray)\n",
    "array of x1-component seismograms, dimension nt x na. ts1[j,k], j in arange(nt), k in arange(na) contains the k’th time sample of the x1 component ground motion at station k. NOTE that the seismogram in column k must correspond to the station whose coordinates are in row k of in.array_coords. nt is the number of time samples in the seismograms. Seismograms may be displacement, velocity, acceleration, jerk, etc. See the “Discussion of input and output units” below.\n",
    "\n",
    "### ts2 (numpy.ndarray)\n",
    "same as ts1, but for the x2 component of motion.\n",
    "\n",
    "### ts3 (numpy.ndarray)\n",
    "same as ts1, but for the x3 (UP or DOWN) component of motion.\n",
    "\n",
    "### sigmau (float or numpy.ndarray)\n",
    "standard deviation (NOT VARIANCE) of ground noise, corresponds to sigma-sub-u in S95 lines above eqn (A5). NOTE: This may be entered as a scalar, vector, or matrix!\n",
    "\n",
    "If sigmau is a scalar, it will be used for all components of all stations.\n",
    "If sigmau is a 1D array of length na, sigmau[i] will be the noise assigned to all components of the station corresponding to array_coords[i,:]\n",
    "If sigmau is a 2D array of dimension na x 3, then sigmau[i,j] is used as the noise of station i, component j.\n",
    "In all cases, this routine assumes that the noise covariance between different stations and/or components is zero.\n",
    "\n",
    "### subarray (numpy.ndarray)\n",
    "NumPy array of subarray stations to use. I.e. if subarray = array([1, 4, 10]), then only rows 1, 4, and 10 of array_coords will be used, and only ground motion time series in the first, fourth, and tenth columns of ts1 will be used. Nplus1 is the number of elements in the subarray vector, and N is set to Nplus1 - 1. To use all stations in the array, set in.subarray = arange(na), where na is the total number of stations in the array (equal to the number of rows of in.array_coords. Sequence of stations in the subarray vector is unimportant; i.e. subarray = array([1, 4, 10]) will yield essentially the same rotations and strains as subarray = array([10, 4, 1]). “Essentially” because permuting subarray sequence changes the d vector, yielding a slightly different numerical result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caution: Running the algorithm several times will cause overlaps as the additonal runs are appended to the existing files\n",
    "Solution: delete the files first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParameters(path2store,t1,t2,array,sub_array):\n",
    "    par = AttribDict()\n",
    "    par.t1 = t1\n",
    "    par.t2 = t2\n",
    "    par.path2store = path2store\n",
    "    par.freqmin = 0.01\n",
    "    par.client = sds.Client(sds_root= \"./data_sds/\")\n",
    "    par.stationxmldir = \"./stationxml/\"\n",
    "    par.array_stations = array\n",
    "    par.sub_array = sub_array\n",
    "    return par\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(par):\n",
    "    start = par.t1\n",
    "    end = par.t2\n",
    "    print(start)\n",
    "\n",
    "# Data Base\n",
    "    localclient = par.client\n",
    "    array_stations = par.array_stations\n",
    "    print(localclient)\n",
    "    print(array_stations)\n",
    "\n",
    "    subarray = par.sub_array\n",
    "\n",
    "    res = []\n",
    "    tsz = []\n",
    "    tsn = []\n",
    "    tse = []\n",
    "    coo = []\n",
    "    first = True\n",
    "    for station in array_stations:\n",
    "        net,sta,stream = station.split(\".\")\n",
    "        stats = localclient.get_waveforms(debug=True,network=net,station=sta,location=\"\",\\\n",
    "                                          channel=stream, starttime=start, endtime=end)\n",
    "        inv = read_inventory(par.stationxmldir + \"*.xml\")\n",
    "        stats.resample(sampling_rate=50)\n",
    "        stats.merge(method=1,fill_value=\"latest\")\n",
    "        stats.attach_response(inv)\n",
    "        stats.remove_sensitivity()\n",
    "        stats.sort()\n",
    "        stats.reverse()\n",
    "        stats.trim(start,end)\n",
    "\n",
    "        if stats.select(component=\"2\"):\n",
    "            stats.rotate(method='->ZNE', inventory=inv, components=['Z23'])\n",
    "        else:\n",
    "            stats.rotate(method='->ZNE', inventory=inv, components=['ZNE'])\n",
    "\n",
    "        l_lon = inv.get_coordinates(stats[0].id,t1)[\"longitude\"]\n",
    "        l_lat = inv.get_coordinates(stats[0].id,t1)[\"latitude\"]\n",
    "        height = inv.get_coordinates(stats[0].id,t1)[\"elevation\"] - inv.get_coordinates(stats[0].id,t1)[\"local_depth\"]\n",
    "        print(stats)\n",
    "        fs = stats[0].stats.sampling_rate\n",
    "        stats.detrend(\"linear\")\n",
    "\n",
    "\n",
    "        stats.detrend(\"simple\")\n",
    "        stats[0].filter('highpass',freq=par.freqmin)\n",
    "        stats[1].filter('highpass',freq=par.freqmin)\n",
    "        stats[2].filter('highpass',freq=par.freqmin)\n",
    "        if first:\n",
    "            first = False\n",
    "            o_lon = l_lon\n",
    "            o_lat = l_lat\n",
    "            o_height = height\n",
    "\n",
    "        lon,lat = util.util_geo_km(o_lon,o_lat,l_lon,l_lat)\n",
    "        coo.append([lon*1000,lat*1000,height-o_height])\n",
    "\n",
    "\n",
    "        tsz.append(stats[0].data)\n",
    "        tsn.append(stats[1].data)\n",
    "        tse.append(stats[2].data)\n",
    "\n",
    "    ttse  =  np.array(tse)\n",
    "    ttsn  =  np.array(tsn)\n",
    "    ttsz  =  np.array(tsz)\n",
    "\n",
    "    subarray = np.array(subarray)\n",
    "    vp = 1000.\n",
    "    vs = 560.\n",
    "    sigmau = 0.0000001\n",
    "    result = AA.array_rotation_strain(subarray, np.transpose(ttse), np.transpose(ttsn), np.transpose(ttsz), vp, vs, np.array(coo), sigmau)\n",
    "\n",
    "    rotz = result['ts_w3']\n",
    "    rotn = result['ts_w2']\n",
    "    rote = result['ts_w1']\n",
    "\n",
    "    straine = result['ts_e'][:,0,0]\n",
    "    strainn = result['ts_e'][:,1,1]\n",
    "    strainz = result['ts_e'][:,2,2]\n",
    "    strainv = result['ts_d']\n",
    "    \n",
    "    _,Ref,_ = array_stations[subarray[0]].split('.')\n",
    "    rots = stats.copy()\n",
    "    rots[0].stats.station = Ref\n",
    "    rots[0].stats.channel = \"BJZ\"\n",
    "    rots[0].stats.location = \"10\"\n",
    "    rots[0].data = rotz\n",
    "    rots[1].stats.station = Ref\n",
    "    rots[1].stats.channel = \"BJN\"\n",
    "    rots[1].stats.location = \"10\"\n",
    "    rots[1].data = rotn\n",
    "    rots[2].stats.station = Ref\n",
    "    rots[2].stats.channel = \"BJE\"\n",
    "    rots[2].stats.location = \"10\"\n",
    "    rots[2].data = rote\n",
    "    rots.detrend(\"simple\")\n",
    "\n",
    "    # and the parameter periods_per_window\n",
    "    rots.trim(start,end)\n",
    "    rots.plot()\n",
    "\n",
    "    myday = str(rots[0].stats.starttime.julday)\n",
    "\n",
    "    pathyear = str(rots[0].stats.starttime.year)\n",
    "    # open catalog file in read and write mode in case we are continuing d/l,\n",
    "    # so we can append to the file\n",
    "    mydatapath = os.path.join(par.path2store, pathyear)\n",
    "\n",
    "    # create datapath \n",
    "    if not os.path.exists(mydatapath):\n",
    "        os.mkdir(mydatapath)\n",
    "\n",
    "    mydatapath = os.path.join(mydatapath, rots[0].stats.network)\n",
    "    if not os.path.exists(mydatapath):\n",
    "        os.mkdir(mydatapath)\n",
    "\n",
    "    mydatapath = os.path.join(mydatapath, rots[0].stats.station)\n",
    "\n",
    "    # create datapath \n",
    "    if not os.path.exists(mydatapath):\n",
    "                os.mkdir(mydatapath)\n",
    "\n",
    "    for i,tr in enumerate(rots):\n",
    "        mydatapathchannel = os.path.join(mydatapath,rots[i].stats.channel + \".D\")\n",
    "\n",
    "        if not os.path.exists(mydatapathchannel):\n",
    "            os.mkdir(mydatapathchannel)\n",
    "\n",
    "        netFile = rots[i].stats.network + \".\" + rots[i].stats.station +  \".\" + rots[i].stats.location + \".\" + rots[i].stats.channel+ \".D.\" + pathyear + \".\" + myday\n",
    "        netFileout = os.path.join(mydatapathchannel, netFile)\n",
    "\n",
    "        # try to open File\n",
    "        try:\n",
    "            netFileout = open(netFileout, 'ab')\n",
    "        except:\n",
    "            netFileout = open(netFileout, 'w')\n",
    "        # header of the stream object which contains the output of the ADR\n",
    "        rots[i].write(netFileout , format='MSEED')\n",
    "        netFileout.close()\n",
    "\n",
    "    return end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['XM.KLT0.BH?','XM.KLT1.SH?','XM.KLT2.SH?','XM.KLT3.SH?']\\\n",
    "['XM.GRW0.BH?','XM.GRW2.SH?','XM.GRW3.SH?']\\\n",
    "['XM.PAS0.BH?','XM.PAS1.SH?','XM.PAS2.SH?']\\\n",
    "['XM.KEN0.BH?','XM.KEN1.SH?','XM.KEN2.SH?','XM.KEN3.SH?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path2store = \"./data_adr\"\n",
    "\n",
    "#\"1998-11-04T22:29\" - \"1998-11-04T22:40\"\n",
    "#\"2001-10-26T05:00\" - \"2001-10-26T05:20\"\n",
    "#\"2001-10-19T14:20\" - \"2001-10-19T16:30\"\n",
    "#\"2001-11-08T14:00\" - \"2001-11-08T14:30\"\n",
    "\n",
    "array=['XM.KLT0.BH?','XM.KLT1.SH?','XM.KLT2.SH?','XM.KLT3.SH?']\n",
    "#array=['XM.GRW0.BH?','XM.GRW1.SH?','XM.GRW2.SH?','XM.GRW3.SH?']\n",
    "#array=['XM.PAS0.BH?','XM.PAS1.SH?','XM.PAS2.SH?']\n",
    "#array=['XM.KEN0.BH?','XM.KEN1.SH?','XM.KEN2.SH?','XM.KEN3.SH?']\n",
    " \n",
    "sub_array = [0,1,2,3]\n",
    "t1 = UTCDateTime(\"1998-11-04T22:29\")\n",
    "t2 = UTCDateTime(\"1998-11-04T22:40\")\n",
    "\n",
    "par = getParameters(path2store,t1,t2,array,sub_array)\n",
    "\n",
    "\n",
    "try:\n",
    "    run(par)\n",
    "except:\n",
    "    print(\"%s failed\"%t1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
