{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c65cd6-3eb8-4762-955c-59f66d3d06e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import optparse\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"AGG\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from obspy.core import UTCDateTime, Stream, AttribDict\n",
    "from obspy import read_inventory\n",
    "from obspy.clients.filesystem import sds\n",
    "from obspy.signal.trigger import coincidence_trigger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aff78d-b390-44c8-86d3-b4c73af8fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sds_root = r\"D:\\DATA\\merapi\\data_sds\"\n",
    "response_root = r\"D:\\DATA\\merapi\\merapi_stationxml.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParameters(network):\n",
    "    par = AttribDict()\n",
    "    par.network = network\n",
    "    par.filter = AttribDict(type=\"bandpass\", freqmin=1.0, freqmax=20.0,\n",
    "                            corners=2, zerophase=True)\n",
    "    trace_ids = {}\n",
    "    if network == \"XM\":\n",
    "        trace_ids = {\"XM.GRW0..BHZ\": 1, \"XM.GRW0..BHN\": 1,\n",
    "                     \"XM.GRW0..BHE\": 1}\n",
    "        coinc_sum = 2.0\n",
    "    elif network == \"XM+\":\n",
    "        trace_ids = {\"XM.GRW0..BHZ\": 1, \"XS.KLT0..BHZ\": 1}\n",
    "        coinc_sum = 2.0\n",
    "\n",
    "    par.trace_ids = trace_ids\n",
    "    # length of sta and lta in seconds\n",
    "    par.coincidence = AttribDict(trigger_type=\"recstalta\", sta=0.5, lta=10,\n",
    "                                 thr_on=4.5, thr_off=0.5,\n",
    "                                 thr_coincidence_sum=coinc_sum,\n",
    "                                 trace_ids=trace_ids, max_trigger_length=120,\n",
    "                                 trigger_off_extension=20)\n",
    "    par.dir = \"./XM_trigger\"\n",
    "    os.makedirs(\"%s\"%par.dir, exist_ok=True)\n",
    "    par.logfile = os.path.join(par.dir, \"%s_log.txt\" % network)\n",
    "    par.trigfile = os.path.join(par.dir, \"%s_trigger.txt\" % network)\n",
    "    return par\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f558b85a-2179-4ab6-83c2-27c486c02268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(time, par):\n",
    "    client = sds.Client(sds_root=sds_root)\n",
    "    t1 = time\n",
    "    t2 = t1 + (60 * 60 * 1) + 10\n",
    "    st = Stream()\n",
    "    num_stations = 0\n",
    "    station_id = []\n",
    "    possible_coinc_sum = 0\n",
    "    exceptions = []\n",
    "    inv = read_inventory(response_root)\n",
    "    for trace_id, weight in par.trace_ids.items():\n",
    "        print(trace_id)\n",
    "        net, sta, loc, cha = trace_id.split(\".\")\n",
    "        station_id.append(\"%s.%s.%s.%s*\"%(net,sta,loc,cha[:-1]))\n",
    "\n",
    "        for comp in \"ZNE123\":\n",
    "            cha_ = cha[:-1] + comp\n",
    "            try:\n",
    "                # we request 60s more at start and end and cut them off later to\n",
    "                # avoid a false trigger due to the tapering during instrument\n",
    "                # correction\n",
    "                tmp = client.get_waveforms(network=net, station=sta, location=loc, channel=cha_, starttime=t1 - 180, endtime=t2 + 180)\n",
    "                tmp.attach_response(inv)\n",
    "            except:\n",
    "                exceptions.append(\"%s-%s\" % (sta,cha_))\n",
    "                continue\n",
    "            if comp == cha[-1]:\n",
    "                possible_coinc_sum += weight\n",
    "            st.extend(tmp)\n",
    "        num_stations += 1\n",
    "    st.merge(-1)\n",
    "    st.sort()\n",
    "\n",
    "    trigger = []\n",
    "    summary = []\n",
    "    summary.append(\"#\" * 79)\n",
    "    summary.append(\"######## %s  ---  %s ########\" % (t1, t2))\n",
    "    summary.append(\"#\" * 79)\n",
    "    summary.append(\"######## %s  ---  %s ########\" % (t1, t2))\n",
    "    summary.append(\"#\" * 79)\n",
    "    summary.append(st.__str__(extended=True))\n",
    "    if exceptions:\n",
    "        summary.append(\"#\" * 33 + \" Exceptions  \" + \"#\" * 33)\n",
    "        summary += exceptions\n",
    "    summary.append(\"#\" * 79)\n",
    "\n",
    "    st.traces = [tr for tr in st if tr.stats.npts > 1]\n",
    "\n",
    "    trig = []\n",
    "    mutt = []\n",
    "    if st:\n",
    "        # preprocessing, backup original data for plotting at end\n",
    "        st.detrend(\"linear\")\n",
    "        st.merge(method=1, fill_value=0)\n",
    "        for tr in st:\n",
    "            perc = 1.0 / (tr.stats.endtime - tr.stats.starttime)\n",
    "            perc = min(perc, 1)\n",
    "            tr.taper(type=\"cosine\", max_percentage=perc)\n",
    "            print(tr)\n",
    "            tr.remove_sensitivity()\n",
    "\n",
    "        st.sort()\n",
    "        st_trigger = st.copy()\n",
    "        # prepare plotting\n",
    "        st.trim(t1, t2, pad=True, fill_value=0)\n",
    "        # triggering\n",
    "        st_trigger.filter(**par.filter)\n",
    "        # do the triggering (with additional data at sides to avoid artifacts\n",
    "        trig = coincidence_trigger(stream=st_trigger, details=True,\n",
    "                                  **par.coincidence)\n",
    "        # restrict trigger list to time span of interest\n",
    "        trig = [t for t in trig if (t1 <= t['time'] <= t2)]\n",
    "\n",
    "        for t in trig:\n",
    "            max_similarity = max(list(t['similarity'].values()) + [0])\n",
    "            time_str = str(t['time']).split(\".\")[0]\n",
    "            sta_string = \"-\".join(t['stations'])\n",
    "            info = \"%s %ss %s %.2f %s\"\n",
    "            info = info % (time_str, (\"%.1f\" % t['duration']).rjust(4),\n",
    "                           (\"%i\" % t['cft_peak_wmean']).rjust(3),\n",
    "                           max_similarity, sta_string)\n",
    "            summary.append(info)\n",
    "            sta_string = \",\".join(station_id)\n",
    "            if t['duration'] < 60:\n",
    "                duration = 60.\n",
    "            else:\n",
    "                duration = t['duration']\n",
    "\n",
    "            info = \"%s %s %s\"%\\\n",
    "                    (par.network, str(t['time'] - 20), str(duration+20))\n",
    "            summary.append(info)\n",
    "            trigger.append(info)\n",
    "            # tmp = st.slice(t['time'] - 10, t['time'] + duration)\n",
    "            # filename = \"%s_%.1f_%i_%s-%s_%.2f_%s.png\"\n",
    "            # filename = filename % (time_str, t['duration'],\n",
    "            #                        t['cft_peak_wmean'], t['coincidence_sum'],\n",
    "            #                        possible_coinc_sum, max_similarity,\n",
    "            #                        sta_string)\n",
    "            # filename = os.path.join(par.dir, filename)\n",
    "            # dpi = 72\n",
    "            # fig = plt.figure(figsize=(700.0 / dpi, 400.0 / dpi))\n",
    "            # for comp, color in zip(\"ENZ123\", \"rrkrrk\"):\n",
    "            #     try:\n",
    "            #         tmp_ = tmp.select(component=comp).copy()\n",
    "            #         tmp_.detrend(\"constant\")\n",
    "            #         tmp_.plot(fig=fig, color=color, number_of_ticks=6,\n",
    "            #               linewidth=1.2, type=\"relative\")\n",
    "            #     except:\n",
    "            #         continue;\n",
    "            # for ax in fig.axes:\n",
    "            #     ylims = ax.get_ylim()\n",
    "            #     ax.set_yticks(ylims)\n",
    "            #     ax.set_yticklabels([\"%.1e\" % (val * 1e3) for val in ylims])\n",
    "            #     ax.set_ylabel(\"mm/s\")\n",
    "            # for ax in fig.axes[::2]:\n",
    "            #     ax.yaxis.set_ticks_position(\"left\")\n",
    "            # for ax in fig.axes[1::2]:\n",
    "            #     ax.yaxis.set_ticks_position(\"right\")\n",
    "            # for ax in fig.axes[:-1]:\n",
    "            #     ax.set_xticks([])\n",
    "            # try:\n",
    "            #     fig.tight_layout()\n",
    "            # except:\n",
    "            #     pass\n",
    "            # fig.subplots_adjust(hspace=0)\n",
    "            # print(filename)\n",
    "            # fig.savefig(filename.replace(\":\",\"_\").replace(\"*\",\"+\"), dpi=dpi)\n",
    "            # plt.close()\n",
    "            # mutt += (\"-a\", filename)\n",
    "        del tmp\n",
    "        del st_trigger\n",
    "        del tr\n",
    "    del st\n",
    "\n",
    "    summary.append(\"#\" * 79)\n",
    "    summary = \"\\n\".join(summary)\n",
    "    trigger = \"\\n\".join(trigger)\n",
    "    # avoid writing long list of streams when using many event templates\n",
    "    par_tmp = par.copy()\n",
    "    #for k, v in par_tmp.coincidence.event_templates.iteritems():\n",
    "    #    par_tmp.coincidence.event_templates[k] = len(v)\n",
    "    summary += \"\\n\" + \"\\n\".join((\"%s=%s\" % (k, v) for k, v in par_tmp.items()))\n",
    "    #print summary\n",
    "    with open(par.logfile, \"wt\") as fh:\n",
    "        fh.write(summary + \"\\n\")\n",
    "    with open(par.trigfile, \"at\") as fu:\n",
    "        fu.write(trigger + \"\\n\")\n",
    "\n",
    "    plt.close('all')\n",
    "    del summary\n",
    "    del trigger\n",
    "    del mutt\n",
    "\n",
    "                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2738fc5-f47d-4304-a4ec-53a78c54890e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setting the inputs\n",
    "\n",
    "t1 = int(UTCDateTime(1998,7,4).timestamp)\n",
    "t2 = int(UTCDateTime(1998,7,16).timestamp)\n",
    "         \n",
    "times = [UTCDateTime(t) for t in np.arange(t1, t2, 3600)]\n",
    "# print(times)\n",
    "\n",
    "network =\"XM\"\n",
    "if network not in (\"XM\", \"XM+\"):\n",
    "    print(\"Not the correct network\")\n",
    "\n",
    "par = getParameters(network)\n",
    "\n",
    "fx = open(par.logfile, \"w\")\n",
    "fx.close()\n",
    "\n",
    "\n",
    "for t in times:\n",
    "    run(t, par)\n",
    "    # print(t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c1496-a752-4317-877d-a464749a3b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103d821-5720-493e-8127-59c3dbca0ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
