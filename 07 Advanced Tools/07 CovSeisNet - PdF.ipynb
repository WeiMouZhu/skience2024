{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tremor location at Piton de la Fournaise\n",
    "This example shows how to calculate the network response function and locate \n",
    "the tremor associated with the 21 June 2014 eruption of the Piton de la Fournaise.\n",
    "\n",
    "Seismic data from 6 stations (only vertical component, downsampled to 20 Hz) are provided for the time period 1 June - 1 July 2014, covering both the pre-eruptive period and the effusive eruption which occurred on the south eastern flank of the volcano.\n",
    "\n",
    "Figures of the current notebook, from top to bottom:  \n",
    "#. Seismic waveform from the vertical component of station FOR, closest to the effusive eruption site  \n",
    "#. Spectral width, between 0.5Hz and 10Hz  \n",
    "#. Average spectral width between 0.3Hz and 5Hz (tremor frequency range)  \n",
    "#. Network response function  \n",
    "#. Likelihood 3-D location  \n",
    "#. Unshifted (before calculating the beam) and shifted (corresponding to the maximum of the beam) cross-correlation envelopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install covseisnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "\n",
    "import covseisnet as csn\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from display import dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = datetime(2014, 6, 20, 21, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READ DATA\n",
    "\n",
    "############\n",
    "# Parameters\n",
    "############\n",
    "starttime = datetime(2014, 6, 20, 20, 0)\n",
    "endtime = starttime + timedelta(minutes=2*60)\n",
    "stations_list = [\n",
    "     ['BON', 55.70921, -21.23971, 2.552],\n",
    "     ['CRA', 55.75783, -21.22336, 0.998],\n",
    "     ['CSS', 55.68451, -21.24642, 2.193],\n",
    "     ['FJS', 55.72229, -21.229493, 2.123],\n",
    "     ['FOR', 55.718708, -21.261867, 2.049],\n",
    "     ['FRE', 55.695393, -21.201837, 1.775],\n",
    "     ['GBS', 55.77934, -21.27387, 0.471],\n",
    "     ['GPN', 55.75247, -21.23979, 1.413],\n",
    "     ['GPS', 55.76162, -21.26741, 1.004],\n",
    "     ['HIM', 55.720224, -21.211121, 1.958],\n",
    "     ['PRA', 55.707912, -21.291698, 2.009],\n",
    "     ['SNE', 55.7179, -21.239115, 2.505]]\n",
    "\n",
    "\n",
    "\n",
    "net = 'PF'\n",
    "year = starttime.year\n",
    "julday = starttime.timetuple().tm_yday\n",
    "\n",
    "data_path = 'XXX/SDS/'\n",
    "data_file = os.path.join(data_path,'{:d}'.format(year),'{:s}'.format(net),\n",
    "             '{:s}','HHZ.D','{:s}.'.format(net)+'{:s}.00.HHZ.D.'+'{:d}.{:03d}'.format(year, julday))\n",
    "\n",
    "############\n",
    "\n",
    "# List of data files\n",
    "datafiles_list = []\n",
    "for station in stations_list:\n",
    "    datafiles_list.append(data_file.format(str(station[0]),str(station[0])))\n",
    "# Stream object\n",
    "stream = csn.arraystream.ArrayStream()\n",
    "# Read if file exists\n",
    "for datafile in datafiles_list:\n",
    "    try:\n",
    "        os.path.isfile(datafile)\n",
    "        stream += csn.arraystream.read(datafile)\n",
    "    except:\n",
    "        print('No file {:s}'.format(datafile))\n",
    "print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA PRE-PROCESSING\n",
    "\n",
    "############\n",
    "# Parameters\n",
    "############\n",
    "# Frequency\n",
    "fdatafilter = [0.01, 9]\n",
    "# Windows / Subwindows\n",
    "window_duration_sec = 60\n",
    "window_average = 16\n",
    "# Spectral pre-processing\n",
    "preprocess_domain = 'spectral'\n",
    "preprocess_method = 'onebit'\n",
    "preprocess_duration_sec = window_duration_sec * (window_average+1) * 0.5\n",
    "############\n",
    "\n",
    "\n",
    "# Pre-processing\n",
    "stream.merge(method=1, interpolation_samples=0, fill_value=0)\n",
    "stream.cut(starttime=starttime, endtime=endtime, pad=True, fill_value=0)\n",
    "stream.detrend(type='demean')\n",
    "stream.filter(type='bandpass', freqmin=fdatafilter[0], freqmax=fdatafilter[1], zerophase=True)\n",
    "stream.sort(keys=['station'])\n",
    "sampling_rate = stream[0].stats.sampling_rate\n",
    "stream.preprocess(domain=preprocess_domain, method=preprocess_method, window_duration_sec=preprocess_duration_sec)\n",
    "stream.cut(starttime=starttime, endtime=endtime, pad=True, fill_value=0)\n",
    "print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CALCULATE SPECTRAL WIDTH\n",
    "\n",
    "# Calculate network covariance matrix\n",
    "times, frequencies, covariances = csn.covariancematrix.calculate(stream, window_duration_sec, window_average)\n",
    "# Calculate spectral width\n",
    "spectral_width = covariances.coherence(kind=\"spectral_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covariances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOT SPECTRAL WIDTH\n",
    "\n",
    "############\n",
    "# Parameters\n",
    "############\n",
    "# Spectral with filtering frequency limits (depends on the target signal)\n",
    "sw_freq_min = 0.3\n",
    "sw_freq_max = 5.0\n",
    "# Station to plot\n",
    "station_plot = ['FOR', 'HHZ']\n",
    "############\n",
    "\n",
    "\n",
    "# Averaged spectral width value\n",
    "i_freq_low = np.argmin(np.abs(frequencies - sw_freq_min))\n",
    "i_freq_high = np.argmin(np.abs(frequencies - sw_freq_max))\n",
    "spectral_width_average = np.mean(spectral_width[:, i_freq_low:i_freq_high], axis=1)\n",
    "\n",
    "# Plot seismic trace from one chosen station and spectral width with its average\n",
    "fig, ax = plt.subplots(3, constrained_layout=True, figsize=(10, 8))\n",
    "\n",
    "# Seismic trace\n",
    "trace_plot = stream.select(station=station_plot[0], channel=station_plot[1])[0].data\n",
    "duration_min = (endtime - starttime).total_seconds() / 60\n",
    "ax[0].plot(np.linspace(0, duration_min, len(trace_plot)), trace_plot, \"k\")\n",
    "ax[0].set_title(\"Vertical channel of station {:s}\".format(station_plot[0]))\n",
    "ax[0].set_ylabel(\"{:s}.{:s} (counts)\".format(station_plot[0], station_plot[1]))\n",
    "ax[0].set_xlim([0, duration_min])\n",
    "\n",
    "# Spectral width\n",
    "img = ax[1].imshow(spectral_width.T,\n",
    "                   origin=\"lower\",\n",
    "                   cmap=\"RdYlBu\",\n",
    "                   interpolation=\"none\",\n",
    "                   extent=[0, duration_min, 0, sampling_rate],\n",
    "                   aspect=\"auto\")\n",
    "ax[1].axhline(sw_freq_min, ls='--', lw=3, c='k')\n",
    "ax[1].axhline(sw_freq_max, ls='--', lw=3, c='k')\n",
    "ax[1].set_ylim([0.1, sampling_rate / 2])\n",
    "ax[1].set_ylabel(\"Frequency (Hz)\")\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].set_title(\"Covariance matrix spectral width\")\n",
    "plt.colorbar(img, ax=ax[1]).set_label(\"Spectral Width\")\n",
    "\n",
    "# Averaged spectral width\n",
    "ax[2].plot(np.linspace(0, duration_min, len(spectral_width_average)), spectral_width_average, \"k\")\n",
    "ax[2].set_title(\"Averaged spectral width between {:.1f}Hz and {:.1f}Hz\".format(sw_freq_min, sw_freq_max))\n",
    "ax[2].set_ylabel(\"Averaged value\")\n",
    "ax[2].set_xlim(0, duration_min)\n",
    "ax[2].set_ylim(np.min(spectral_width), np.max(spectral_width))\n",
    "ax[2].set_xlabel(\"Minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPUTE NETWORK RESPONSE FUNCTION (NRF)\n",
    "\n",
    "############\n",
    "# Parameters\n",
    "############\n",
    "# Path to traveltime grids\n",
    "traveltime_filepath = \"XX/PdF/ttimes/\"  # path to traveltime grids\n",
    "\n",
    "# grid extent Longitude: 55.67째 to 55.81째 (145 points), Latitude: -21.3째 to -21.2째 (110 points)\n",
    "lon_min = 55.67\n",
    "lon_max = 55.81\n",
    "lat_min = -21.3\n",
    "lat_max = -21.2\n",
    "depth_min = -2.6  # edifice summit (km)\n",
    "depth_max = 3.0  # max depth of traveltime grids (km)\n",
    "\n",
    "\n",
    "\n",
    "# Correlation filtering\n",
    "fxcorr_low_pass = 0.3\n",
    "fxcorr_high_pass = 5.0\n",
    "# Correlation Smoothing\n",
    "sigma = 20\n",
    "############\n",
    "\n",
    "# Eigenvector decomposition - covariance matrix filtered by the 1st eigenvector to show the dominant source\n",
    "covariance_1st = covariances.eigenvectors(covariance=True, rank=0)\n",
    "\n",
    "# Extract cross-correlations\n",
    "lags, correlation = csn.correlationmatrix.cross_correlation(covariance_1st, sampling_rate)\n",
    "\n",
    "# Load traveltimes grid from npy pre-calculated files\n",
    "traveltimes = csn.traveltime.TravelTime(stream, traveltime_filepath)\n",
    "\n",
    "# Initiate beam object and set geographical extent of grid\n",
    "nwin = correlation.nwin()  # number of time windows\n",
    "beam = csn.beam.Beam(nwin, traveltimes)\n",
    "beam.set_extent(lon_min, lon_max, lat_min, lat_max, depth_min, depth_max)\n",
    "\n",
    "# Loop through all time windows and calculate likelihood and nrf for each window\n",
    "for i in range(0, nwin):\n",
    "    print(\"Processing window {:d} of {:d}\".format(i, nwin-1))\n",
    "\n",
    "    correl = correlation[i]\n",
    "\n",
    "    # Correlation filtering\n",
    "    correl = correl.bandpass(fxcorr_low_pass, fxcorr_high_pass, sampling_rate)\n",
    "\n",
    "    # Correlation enveloppe\n",
    "    correl = correl.hilbert_envelope()\n",
    "    \n",
    "    # Envelope smoothing\n",
    "    correl = correl.smooth(sigma=sigma)\n",
    "\n",
    "    beam.calculate_likelihood(correl, sampling_rate, i)\n",
    "    beam.calculate_nrf(i)\n",
    "\n",
    "    beam_max = beam.max_likelihood(i)\n",
    "    print(\"Maximum likelihood at Lon={:.2f}, Lon={:.2f}, Depth={:.2f} km\".format(beam_max[0],\n",
    "                                                                                 beam_max[1],\n",
    "                                                                                 beam_max[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOT NRF\n",
    "\n",
    "fig, ax = plt.subplots(1, constrained_layout=True, figsize=(10, 3))\n",
    "ax.plot(np.linspace(0, duration_min, nwin), beam.nrf, \"k\")\n",
    "t=np.linspace(0, duration_min, nwin)\n",
    "ax.set_title(\"Network response function (NRF)\")\n",
    "ax.set_ylabel(\"NRF, unormalized\")\n",
    "ax.set_xlim(0, duration_min)\n",
    "ax.set_xlabel(\"Minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOT 3-D LIKELIHOOD\n",
    "\n",
    "############\n",
    "# Parameters\n",
    "############\n",
    "# Choose the window index for plotting likelihood\n",
    "i_win = 5\n",
    "# Dem\n",
    "demfile = \"XX/PdF/dem/dem.asc\"\n",
    "depth_plot_lim = -3  # in km\n",
    "# Eruption sites\n",
    "\n",
    "############\n",
    "\n",
    "\n",
    "# Extract max likelihood position\n",
    "beam_max = beam.max_likelihood(i_win)\n",
    "x_max = beam_max[0]\n",
    "y_max = beam_max[1]\n",
    "z_max = beam_max[2]\n",
    "\n",
    "# Select likelihood\n",
    "likelihood_xyz = beam.likelihood[i_win, :, :, :]\n",
    "\n",
    "# Normalize likelihood betwwen 0 and 1\n",
    "likelihood_xyz = (likelihood_xyz - likelihood_xyz.min()) / (likelihood_xyz.max() - likelihood_xyz.min())\n",
    "\n",
    "# Take slices at point of max likelihood\n",
    "i_max, j_max, k_max = np.unravel_index(likelihood_xyz.argmax(), likelihood_xyz.shape)\n",
    "likelihood_xy = likelihood_xyz[:, :, k_max]\n",
    "likelihood_xz = likelihood_xyz[:, j_max]\n",
    "likelihood_yz = likelihood_xyz[i_max]\n",
    "\n",
    "# Create custom discrete colormap for likelihood\n",
    "custom_cmap = plt.cm.get_cmap(\"RdYlBu_r\")(np.linspace(0, 1, 12))\n",
    "for i in range(4):\n",
    "    custom_cmap[i, :] = [1, 1, 1, 1]\n",
    "for i in range(1, 12):\n",
    "    custom_cmap[i, -1] = np.sqrt(i / 12)\n",
    "custom_cmap = mcolors.LinearSegmentedColormap.from_list(\"RdYlBu_r\", custom_cmap, N=16)\n",
    "\n",
    "# Create figure\n",
    "gs = dict(width_ratios=[2.5, 1], height_ratios=[2, 1], wspace=0.05, hspace=0.01)\n",
    "fig, ax = plt.subplots(2, 2, constrained_layout=True, figsize=(7, 6), gridspec_kw=gs, dpi=100)\n",
    "ax = ax.ravel()\n",
    "\n",
    "# MAP VIEW\n",
    "# Likelihood\n",
    "ax[0].imshow(likelihood_xy.T, interpolation=\"none\", origin=\"lower\", cmap=custom_cmap, aspect=\"auto\",\n",
    "    extent=[lon_min, lon_max, lat_min, lat_max], vmin=0.0)\n",
    "# Plot stations\n",
    "for station in stations_list:\n",
    "    ax[0].plot(station[1], station[2], \"v\", mfc='k', mec='k', mew=0.4, ms=10)\n",
    "    ax[0].text(station[1]+0.005, station[2]-0.001, station[0])\n",
    "# Plot eruption sites\n",
    "#for eruption in eruptions_list:\n",
    "#    ax[0].plot(eruption[0], eruption[1], \"o\", mfc='lime', mec='k', mew=0.4, ms=6)\n",
    "# Max likelihood position\n",
    "ax[0].plot(x_max, y_max, \"*\", mfc='w', mec='k', mew=0.4, ms=10)\n",
    "    \n",
    "# DEPTH VIEWS\n",
    "\n",
    "# Extract dem infos\n",
    "dem_lon, dem_lat, dem_alt = dem.read(demfile, depth_factor=-1e-3)\n",
    "dem_alt_lon = np.nanmin(dem_alt, axis=0)\n",
    "dem_alt_lat = np.nanmin(dem_alt, axis=1)\n",
    "\n",
    "# DEPTH-LONGITUDE VIEW\n",
    "# Likelihood\n",
    "ax[2].imshow(likelihood_xz.T, interpolation=\"none\", origin=\"upper\", cmap=custom_cmap, aspect=\"auto\",\n",
    "    extent=[lon_min, lon_max, depth_max, depth_min], vmin=0.0)\n",
    "# Crop out data above topo\n",
    "ax[2].fill_between(dem_lon, depth_plot_lim-1, dem_alt_lon, facecolor='w', edgecolor='k', lw=.4)\n",
    "# Max likelihood position\n",
    "ax[2].plot(x_max, z_max, \"*\", mfc='w', mec='k', mew=0.4, ms=10)\n",
    "\n",
    "# DEPTH-LATITUDE VIEW\n",
    "# Likelihood\n",
    "img_yz = ax[1].imshow(likelihood_yz, interpolation=\"none\", origin=\"lower\", cmap=custom_cmap, aspect=\"auto\",\n",
    "    extent=[depth_min, depth_max, lat_min, lat_max], vmin=0.0)\n",
    "# Crop out data above topo\n",
    "ax[1].fill_betweenx(dem_lat, depth_plot_lim-1, dem_alt_lat, facecolor='w', edgecolor='k', lw=.4)\n",
    "# Max likelihood position\n",
    "ax[1].plot(z_max, y_max, \"*\", mfc='w', mec='k', mew=0.4, ms=10)\n",
    "\n",
    "# Cosmetics\n",
    "ax[0].set_xticklabels([])\n",
    "ax[0].set_ylabel(\"Latitude\")\n",
    "ax[1].set_xlabel(\"Depth (km)\")\n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_xlim([depth_plot_lim, depth_max])\n",
    "ax[1].set_ylim([lat_min, lat_max])\n",
    "ax[2].set_xlabel(\"Longitude\")\n",
    "ax[2].set_ylabel(\"Depth (km)\")\n",
    "ax[2].set_xlim([lon_min, lon_max])\n",
    "ax[2].set_ylim([depth_max, depth_plot_lim])\n",
    "\n",
    "# Colorbar\n",
    "cb = plt.colorbar(img_yz, cax=ax[3], orientation='horizontal')\n",
    "cb.set_label('Likelihood')\n",
    "cb.set_ticks([0, 1 / 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOT CROSS-CORRELATIONS ENVELOPES\n",
    "\n",
    "############\n",
    "# Parameters\n",
    "############\n",
    "stack_lim = [0, 0.125]\n",
    "############\n",
    "\n",
    "# Create figure\n",
    "gs = dict(width_ratios=[1, 1], height_ratios=[4, 1], wspace=0.10, hspace=0.10)\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 10), gridspec_kw=gs, dpi=100)\n",
    "\n",
    "# Index\n",
    "idx = 0\n",
    "\n",
    "# Loop over unshifted and shifted cases\n",
    "for xcorr_label, xcorr in ((\"Unshifted envelopes\", beam.correlation_unshifted[i_win]),\n",
    "    (\"Shifted envelopes\", beam.correlation_shifted[i_win])):\n",
    "    \n",
    "    # Extract\n",
    "    lag_max = np.max(lags) / 2\n",
    "    xcorr_max = np.nanmax(xcorr)\n",
    "\n",
    "    # Plot\n",
    "    n_xcorr = xcorr.shape[0]\n",
    "    for d, x in zip(range(1, n_xcorr + 1), xcorr):\n",
    "        x = 0.5 * np.abs(x) / xcorr_max\n",
    "        ax[0, idx].fill_between(lags, -x + d, x + d, facecolor=\"b\", alpha=0.5)\n",
    "    ax[1, idx].plot(lags, np.nansum(xcorr, axis=0), c=\"b\", lw=1.0)\n",
    "\n",
    "    # Cosmetics\n",
    "    ax[0, idx].set_title(xcorr_label, loc=\"left\", va=\"bottom\", size=10)\n",
    "    ax[0, idx].set_xlim([-lag_max, lag_max])\n",
    "    ax[0, idx].set_ylim([0, n_xcorr + 1])\n",
    "    ax[0, idx].set_yticks(range(1, n_xcorr + 1))\n",
    "    ax[0, idx].set_xticklabels([])\n",
    "    ax[0, idx].set_yticklabels([])\n",
    "    ax[1, idx].set_title(\"Envelopes stack\", loc=\"left\", va=\"bottom\", size=10)\n",
    "    ax[1, idx].set_xlim([-lag_max, lag_max])\n",
    "    ax[1, idx].set_ylim(np.array(stack_lim)*2)\n",
    "    ax[1, idx].set_xlabel(\"Lag (sec)\", fontsize=10)\n",
    "    ax[0, idx].tick_params(which=\"both\", direction=\"out\", labelsize=7)\n",
    "    ax[1, idx].tick_params(which=\"both\", direction=\"out\", labelsize=7)\n",
    "    \n",
    "    # Index incrementation\n",
    "    idx += 1\n",
    "\n",
    "# Cosmetics\n",
    "ax[0, 0].set_ylabel(\"Station pairs\", fontsize=10)\n",
    "ax[1, 0].set_ylabel(\"Stack\", fontsize=10)\n",
    "ax[1, 1].set_yticklabels([])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
