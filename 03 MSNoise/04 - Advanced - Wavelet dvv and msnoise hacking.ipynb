{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02dc474-f360-49ba-a69a-5cfa2a7258b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\")) \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from obspy import read, UTCDateTime, read_inventory\n",
    "from obspy.signal import PPSD\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.dates import DateFormatter\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import matplotlib as mpl\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from msnoise.api import *\n",
    "from wxs_dvv import *\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (16,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9502e553-3d0b-4b0f-8aba-a13ab616a723",
   "metadata": {},
   "source": [
    "# Compute dv/v using the wavelet method\n",
    "\n",
    "Following the excercise exploring the classical (MWCS) processing of continuous seismic records for monitoring using seismic interferometry with MSNoise, we now explore a different way to measure relative variations of seismic velocity from cross-correlation functions (CCFs). We just explored increasing the the temporal resolution with sub-daily processing, we are now exploring increasing the spectral resolution and its benefits.\n",
    "\n",
    "Shujuan Mao's paper\n",
    "\n",
    "The Wavelet method presents particular benefit when monitoring volcanoes as it provides a proxy for the depth of one, or several potential sources of pressurization under a volcano which, in turn, can be critical to forecasting an eruption or understanding its co-eruptive behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2f72e-8d10-4dd6-b6a9-2598046cb889",
   "metadata": {},
   "source": [
    "- Here we will try and reproduce the dv/v measurements for the same 3 stations of the Piton de la Fournaise volcano, picking up after the stacking step. Here we are using the wavelet method, meaning that we can easily adjust the frequeny range of interest after processing the CCFs\n",
    "- While you do this exercise, think about the advatange this method can have over the MWCS, but also its disadvantages.\n",
    "- This provides also another template for how you can hack into MSNoise to develop you own methodologies, for monitoring or any other applications!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08b673-9043-4071-a0ec-e38cb1129f53",
   "metadata": {},
   "source": [
    "## Getting parameters from the msnoise DB\n",
    "\n",
    "Again, when pluging into an MSNoise workflow, you can always use the parameters as they are in the database, or modify them below to explore the results (e.i. Start, end freqmin, freqmax, mov_stack,...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f41fb-32ed-4976-90dc-a03eb2ffee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the database\n",
    "db = connect()\n",
    "\n",
    "# Obtain a list of dates between ``start_date`` and ``enddate``\n",
    "start, end, datelist = build_movstack_datelist(db)\n",
    "\n",
    "# Get the list of parameters from the DB:\n",
    "params = get_params(db)\n",
    "\n",
    "# Get the time axis for plotting the CCF:\n",
    "taxis = get_t_axis(db)\n",
    "\n",
    "filter_id = 5\n",
    "comp = \"EN\"\n",
    "\n",
    "station= \"PF.CSS.00\"\n",
    "\n",
    "pair=\"{}:{}\".format(station,station)\n",
    "\n",
    "# Get the results for two station, filter id=1, ZZ component, mov_stack=(\"1d\",\"1d\") and the results as a 2D array:\n",
    "ccfs = get_results_all(db, station, station, filter_id, comp, datelist, format=\"xarray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d861c-cf17-4665-b535-9e1e2cec3e62",
   "metadata": {},
   "source": [
    "# Reading the CCFs\n",
    "Let's first take a look at an individual trace and it's corresponding reference trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27263af-00c3-4a10-8d8f-cac4e59fb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=ccfs.CCF.median(axis=0).data\n",
    "cur_trace = ccfs.CCF[955]\n",
    "current = cur_trace.data\n",
    "t = ccfs.CCF.mean(axis=0).taxis.data\n",
    "# We normalise the traces here\n",
    "ori_waveform = (ref/ref.max())\n",
    "new_waveform = (current/current.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9326e86-37bb-4aa0-b728-fda726c81f99",
   "metadata": {},
   "source": [
    "Go ahead and plot it! have fun with the figure too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fff814-2464-49d0-a56b-d02be624030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(t,new_waveform, label=\"individual trace\", alpha=0.7)\n",
    "plt.plot(t,ori_waveform, label=\"Reference\")\n",
    "\n",
    "plt.xlim(-50,50)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec01e4e-2743-44fd-9bdc-47d6d9186310",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = get_filters(db, all=False)\n",
    "\n",
    "# We areworking with the broad-ish frequency range of the filter 5\n",
    "freqmin=filters[0].low\n",
    "freqmax=filters[0].high\n",
    "fs = params.cc_sampling_rate\n",
    "lag_min = params.dtt_minlag\n",
    "lag_max = params.dtt_minlag+params.dtt_width\n",
    "\n",
    "date = cur_trace.times.data # The time of the current trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff63a997-47e9-4371-bff8-ad4a3a270573",
   "metadata": {},
   "source": [
    "## The cross-wavelet transform\n",
    "Now we use the same function described in Shujuan's paper on both traces\n",
    "\n",
    "The inputs are the following:\n",
    "\n",
    "    trace_ref,\n",
    "    trace_current,\n",
    "    fs, Sampling frequency --> extracted from the DB\n",
    "    ns, smoothing parameter\n",
    "    nt, smoothing parameter\n",
    "    vpo, Spacing parameter between discrete scales, higher means finer resolution\n",
    "    freqmin,\n",
    "    freqmax,\n",
    "    nptsfreq, Number of frequency points between freqmin and freqmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da2dd4-37bb-480d-ad89-0a82a29e63c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross wavelet transform\n",
    "WXamp, WXspec, WXangle, Wcoh, WXdt, freqs, coi = xwt(ori_waveform, new_waveform, fs, 3, 0.25, 10, freqmin, freqmax, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cbab62-01f0-4e0a-8574-2413f7f1475a",
   "metadata": {},
   "source": [
    "While most of the magic happened in the cell above, we still don't have a dv/v.\n",
    "For this we will calculate a similar linear regression as the one discussed yesterday for the MWCS method. Here, however, we calculate it for every frequency point and using a weighting function rejecting data point with low coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7968eda-3818-4e30-ae1d-ef32ad34fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dv/v from the linear regression and the weighting function\n",
    "dvv, err, wf =get_dvv(freqs, t, WXamp, Wcoh, WXdt, lag_min, lag_max, freqmin=freqmin, freqmax=freqmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd16642-cb04-45ea-bbe2-88d0c31cdee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the results\n",
    "do_plot(t, WXamp, WXspec, WXangle, Wcoh, WXdt, freqs, coi, wf, pair, date, comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22670e8f-5269-494b-895f-0957c72b03bc",
   "metadata": {},
   "source": [
    "Now you will find the figure in \"WCT/Figure\", let's talk about what it means..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a5046d-f098-4c5d-919b-1ee6f47b9508",
   "metadata": {},
   "source": [
    "# Going bigger\n",
    "Now let's run the job for all dates and all components available. This might take a while, so start with a subset of dates in the time_range variable. Try something like `time_range = ccfs.times.data[910:960]` to work on only 50 time steps at the time. With enough time, try to look at the output for all 3 stations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3b3a8-236d-4a68-adf3-8f4bc7fdb4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = False\n",
    "saveit=False\n",
    "import tqdm\n",
    "comps=[\"EN\", \"EZ\", \"NZ\"]\n",
    "fig, axes = plt.subplots(len(comps),1, figsize=(10,10))\n",
    "filterid = 5\n",
    "taxis = get_t_axis(db)\n",
    "mov_stack = params.mov_stack[-1]\n",
    "s1 = 'PF.FOR.00'\n",
    "s2 = s1\n",
    "\n",
    "iax=0\n",
    "\n",
    "plt.suptitle(mov_stack)\n",
    "filter = get_filters(db, ref=filterid)\n",
    "for i, comp in enumerate(comps):\n",
    "    plt.sca(axes[iax])      \n",
    "    try:\n",
    "        ref = xr_get_ref(s1, s2, comp, filterid, taxis)\n",
    "        ref = ref.CCF.values\n",
    "        ori_waveform = (ref/ref.max()) #TODO make normalisation optional\n",
    "    except FileNotFoundError as fullpath:\n",
    "        print(\"FILE DOES NOT EXIST: %s, skipping\" % fullpath)\n",
    "        continue\n",
    "    if not len(ref):\n",
    "        continue                \n",
    "    dvv_list = []\n",
    "    err_list = []\n",
    "    data_dates = []\n",
    "    try:\n",
    "        ccfs = get_results_all(db, s1, s2, filter_id, comp, datelist, format=\"xarray\")\n",
    "    except FileNotFoundError as fullpath:\n",
    "        print(\"FILE DOES NOT EXIST: %s, skipping\" % fullpath)\n",
    "        continue\n",
    "    print(\"Processing %s:%s f%i m%s %s\" % (s1, s2, filterid, mov_stack, comp))\n",
    "    ### TIME RANGE can be edited here!\n",
    "    time_range = ccfs.times.data[910:960]\n",
    "    pbar = tqdm.tqdm(time_range, desc=\"looping through dates\")\n",
    "    for d, date in enumerate(pbar):        \n",
    "\n",
    "        pbar.set_description(\"looping through dates {}\".format(date))\n",
    "        current = ccfs.CCF[d].values\n",
    "        new_waveform = (current/current.max())\n",
    "        \n",
    "        WXamp, WXspec, WXangle, Wcoh, WXdt, freqs, coi = xwt(ori_waveform, new_waveform, fs, 3, 0.25, 10, freqmin, freqmax, 400)# TODO get freq lims from db \n",
    "        dvv, err, wf =get_dvv(freqs, t, WXamp, Wcoh, WXdt, lag_min, lag_max, freqmin=freqmin, freqmax=freqmax)\n",
    "        dvv_list.append(dvv)\n",
    "        err_list.append(err)\n",
    "        data_dates.append(date)\n",
    "        if plot:\n",
    "            do_plot(t, WXamp, WXspec, WXangle, Wcoh, WXdt, freqs, coi, wf, pair, date, comp)\n",
    "#                    del dvv, err\n",
    "\n",
    "    if len(dvv_list)>1: # Check if the list has more than 1 measurement to save it\n",
    "        dvv_df = pd.DataFrame(columns=freqs, index=data_dates)\n",
    "        err_df = pd.DataFrame(columns=freqs, index=data_dates)\n",
    "        pbar = tqdm.tqdm(data_dates, desc=\"Formating the DataFrame\")\n",
    "        for i, date in enumerate(pbar):\n",
    "            dvv_df.iloc[i]=dvv_list[i]\n",
    "            err_df.iloc[i]=err_list[i]\n",
    "        if saveit:\n",
    "            if not os.path.isdir(\"WCT\"):\n",
    "                os.makedirs(\"WCT\")\n",
    "            dfn = \"{} {}_ {} - {}.pkl\".format(pair.replace(\":\",\"_\"),comp,str(dvv_df.index[0].date()),str(dvv_df.index[-1].date()))\n",
    "            efn = \"Err {} {}_ {} - {}.pkl\".format(pair.replace(\":\",\"_\"),comp,str(dvv_df.index[0].date()),str(dvv_df.index[-1].date()))\n",
    "            path = os.path.join(\"WCT\",dfn)\n",
    "            epath = os.path.join(\"WCT\",efn)\n",
    "            dvv_df.to_pickle(path)    # Save dvv\n",
    "            err_df.to_pickle(epath)\n",
    "\n",
    "\n",
    "    clim = 2\n",
    "    span = 30 # Smoothing alert!\n",
    "    axes[iax].pcolormesh(np.asarray(dvv_df.ewm(span = span).mean().index), \n",
    "                   np.asarray(dvv_df.ewm(span = span).mean().columns), \n",
    "                   dvv_df.ewm(span = span).mean().astype(float).T.values, \n",
    "                   cmap='seismic_r', edgecolors='none', vmin=-clim, vmax=clim)\n",
    "    axes[iax].set_ylim(0.5, 2)\n",
    "    cmap = mpl.cm.seismic_r\n",
    "    norm = mpl.colors.Normalize(vmin=-clim, vmax=clim)\n",
    "    cbar2=plt.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),ax = axes[iax])\n",
    "    cbar2.set_label('dv/v', rotation=270)\n",
    "    plt.title(\"Filter %i (%.2f - %.2f Hz) - %s\" % (filterid, 0.5, 2, comp))            \n",
    "    plt.axvline(datetime.date(2014,6,21), c='r', ls='--')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    iax+=1\n",
    "plt.tight_layout()\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb5f29d-138a-45d4-9a31-3103d8880eae",
   "metadata": {},
   "source": [
    "When you manage to process the whole period, you are looking at the dv/v between 0.5 and 2 Hz at a high spectral resolution. Take some time to think about what you are looking at."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42573069-5770-4d80-9525-2060e8d507e9",
   "metadata": {},
   "source": [
    "If you have extra time on your hands, try and average ths wavelet plot across the same frequency ranges in the filters precessed in the first notebook to campare the result with the one preduced with the MWCS method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759924e2-8b06-4328-b79b-a90d76957459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
